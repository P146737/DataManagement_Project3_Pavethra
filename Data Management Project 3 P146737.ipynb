{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ff9c09-18c9-4b0c-bd6e-3238821148cf",
   "metadata": {},
   "source": [
    "## Cassandra Keyspace and Table setup\n",
    "\n",
    "The Cassandra keyspace and tables were pre-created using the following commands. This is to ensure a smooth write-read pipeline between Spark and Cassandra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee64ea1-506c-496f-9890-621d53b82e6b",
   "metadata": {},
   "source": [
    "CREATE TABLE movielens.users (\n",
    "    user_id int PRIMARY KEY,\n",
    "    age int,\n",
    "    gender text,\n",
    "    occupation text,\n",
    "    zip_code text\n",
    ")\n",
    "\n",
    "CREATE TABLE movielens.movies (\n",
    "    movie_id int PRIMARY KEY,\n",
    "    imdb_url text,\n",
    "    release_date text,\n",
    "    title text,\n",
    "    video_release_date text\n",
    ")\n",
    "\n",
    "CREATE TABLE movielens.ratings (\n",
    "    movie_id int,\n",
    "    user_id int,\n",
    "    rating int,\n",
    "    timestamp text,\n",
    "    PRIMARY KEY (movie_id, user_id)\n",
    ")\n",
    "\n",
    "CREATE TABLE movielens.users_under_20 (\n",
    "    user_id int PRIMARY KEY,\n",
    "    age int,\n",
    "    gender text,\n",
    "    occupation text,\n",
    "    zip_code text\n",
    ")\n",
    "\n",
    "CREATE TABLE movielens.scientists_30_40 (\n",
    "    user_id int PRIMARY KEY,\n",
    "    age int,\n",
    "    gender text,\n",
    "    occupation text,\n",
    "    zip_code text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a671e4-c234-42a3-865c-d267203e6521",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "Setting up the required libraries, Spark session and environment paths. This is to ensure that Spark can interact with Cassandra correctly on the local instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedf4c08-7023-4e55-ae38-3d6c8a0d4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, desc, col, count\n",
    "from pyspark.sql.functions import col, array, lit, when, expr\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from cassandra.cluster import Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5656f8b2-374a-4cab-8029-64a13574c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/opt/anaconda3/envs/sparkenv38/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/opt/anaconda3/envs/sparkenv38/bin/python\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dac10c3-3241-4860-b825-897d83185cd3",
   "metadata": {},
   "source": [
    "## Start Spark Session\n",
    "\n",
    "This is to initialize the SparkSession and connect it to the local Cassandra instance. This is essential to enable reading/writing data into the Cassandra database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "684fa16f-e732-4748-bf35-45b116bf8ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/21 16:18:09 WARN Utils: Your hostname, Pavethras-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.104 instead (on interface en0)\n",
      "25/07/21 16:18:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.4.1/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/pavethraavadiar/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/pavethraavadiar/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c61da60a-9d1d-400b-bb28-04362dd9dcb3;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.4.1 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      ":: resolution report :: resolve 238ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.4.1 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   19  |   0   |   0   |   0   ||   19  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c61da60a-9d1d-400b-bb28-04362dd9dcb3\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 19 already retrieved (0kB/5ms)\n",
      "25/07/21 16:18:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/21 16:18:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MovieLensAnalysis\") \\\n",
    "    .config(\"spark.cassandra.connection.host\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.cassandra.connection.port\", \"9042\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d48216f1-6ab4-41b8-8b07-827570761585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver Python: 3.8.20 (default, Oct  3 2024, 10:22:23) \n",
      "[Clang 14.0.6 ]\n",
      "PYSPARK_PYTHON: /opt/anaconda3/envs/sparkenv38/bin/python\n",
      "PYSPARK_DRIVER_PYTHON: /opt/anaconda3/envs/sparkenv38/bin/python\n"
     ]
    }
   ],
   "source": [
    "print(\"Driver Python:\", sys.version)\n",
    "print(\"PYSPARK_PYTHON:\", os.environ.get(\"PYSPARK_PYTHON\"))\n",
    "print(\"PYSPARK_DRIVER_PYTHON:\", os.environ.get(\"PYSPARK_DRIVER_PYTHON\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b233925-5e59-40de-b51c-0248e961e7e7",
   "metadata": {},
   "source": [
    "## Loading and Processing User Data ('u.user' file)\n",
    "\n",
    "This step is to parse the pipe-separated user file and convert the RDD to a DataFrame with appropriate column names and data types. Renaming \"zip\" to \"zip_code\" improves clarity and schema compatibility. This data will later be written to Cassandra for persistence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65149fde-ea75-4c47-9ae3-d9bb9534d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_users(file_path):\n",
    "    users_rdd = spark.sparkContext.textFile(file_path)\n",
    "    users_parsed = users_rdd.map(lambda x: x.split(\"|\"))\n",
    "    users_df = users_parsed.map(lambda u: (int(u[0]), int(u[1]), u[2], u[3], u[4])) \\\n",
    "        .toDF([\"user_id\", \"age\", \"gender\", \"occupation\", \"zip\"])\n",
    "    return users_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a17f44d-58a8-4400-a532-6068ba3a3ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-------------+-----+\n",
      "|user_id|age|gender|   occupation|  zip|\n",
      "+-------+---+------+-------------+-----+\n",
      "|      1| 24|     M|   technician|85711|\n",
      "|      2| 53|     F|        other|94043|\n",
      "|      3| 23|     M|       writer|32067|\n",
      "|      4| 24|     M|   technician|43537|\n",
      "|      5| 33|     F|        other|15213|\n",
      "|      6| 42|     M|    executive|98101|\n",
      "|      7| 57|     M|administrator|91344|\n",
      "|      8| 36|     M|administrator|05201|\n",
      "|      9| 29|     M|      student|01002|\n",
      "|     10| 53|     M|       lawyer|90703|\n",
      "|     11| 39|     F|        other|30329|\n",
      "|     12| 28|     F|        other|06405|\n",
      "|     13| 47|     M|     educator|29206|\n",
      "|     14| 45|     M|    scientist|55106|\n",
      "|     15| 49|     F|     educator|97301|\n",
      "|     16| 21|     M|entertainment|10309|\n",
      "|     17| 30|     M|   programmer|06355|\n",
      "|     18| 35|     F|        other|37212|\n",
      "|     19| 40|     M|    librarian|02138|\n",
      "|     20| 42|     F|    homemaker|95660|\n",
      "+-------+---+------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df = load_users(\"/Users/pavethraavadiar/Documents/Masters - Sem 2/Data management/project 3/ml-100k/u.user\")\n",
    "users_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee85e02-b7e6-46d5-b5a6-1a9ad998b54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-------------+--------+\n",
      "|user_id|age|gender|   occupation|zip_code|\n",
      "+-------+---+------+-------------+--------+\n",
      "|      1| 24|     M|   technician|   85711|\n",
      "|      2| 53|     F|        other|   94043|\n",
      "|      3| 23|     M|       writer|   32067|\n",
      "|      4| 24|     M|   technician|   43537|\n",
      "|      5| 33|     F|        other|   15213|\n",
      "|      6| 42|     M|    executive|   98101|\n",
      "|      7| 57|     M|administrator|   91344|\n",
      "|      8| 36|     M|administrator|   05201|\n",
      "|      9| 29|     M|      student|   01002|\n",
      "|     10| 53|     M|       lawyer|   90703|\n",
      "|     11| 39|     F|        other|   30329|\n",
      "|     12| 28|     F|        other|   06405|\n",
      "|     13| 47|     M|     educator|   29206|\n",
      "|     14| 45|     M|    scientist|   55106|\n",
      "|     15| 49|     F|     educator|   97301|\n",
      "|     16| 21|     M|entertainment|   10309|\n",
      "|     17| 30|     M|   programmer|   06355|\n",
      "|     18| 35|     F|        other|   37212|\n",
      "|     19| 40|     M|    librarian|   02138|\n",
      "|     20| 42|     F|    homemaker|   95660|\n",
      "+-------+---+------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_users(file_path):\n",
    "    users_rdd = spark.sparkContext.textFile(file_path)\n",
    "    users_parsed = users_rdd.map(lambda x: x.split(\"|\"))\n",
    "    users_df = users_parsed.map(lambda u: (int(u[0]), int(u[1]), u[2], u[3], u[4])) \\\n",
    "        .toDF([\"user_id\", \"age\", \"gender\", \"occupation\", \"zip\"])\n",
    "    return users_df\n",
    "\n",
    "users_df = load_users(\"/Users/pavethraavadiar/Documents/Masters - Sem 2/Data management/project 3/ml-100k/u.user\")\n",
    "users_df = users_df.withColumnRenamed(\"zip\", \"zip_code\")\n",
    "users_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e85829e-600f-4af7-b45a-803503f8e5e5",
   "metadata": {},
   "source": [
    "## Writing users data into Cassandra\n",
    "\n",
    "In the next step, the processed users DataFrame was persisted into the Cassandra keyspace 'movielens', under the 'users' table. This is to save clean data for reuse purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c11a283-32ef-4abb-bb5d-d68244df44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .options(table=\"users\", keyspace=\"movielens\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03e31ac0-1373-41d9-8678-a9aea7c23f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afb4668-7f07-403f-80ea-16b2bad25970",
   "metadata": {},
   "source": [
    "## Load and Process Movies data ('u.item')\n",
    "\n",
    "In the next step, only the first 5 columns of the movie metadata, which are the most relevant for basic analysis are loaded. This is to focus on the essential features like movie_id, title, and release_date. Additional genre information is also included for extended analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a575cb45-2bbe-4f29-9cd3-b27e5e8dfad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+------------+------------------+--------------------+\n",
      "|movie_id|            title|release_date|video_release_date|            imdb_url|\n",
      "+--------+-----------------+------------+------------------+--------------------+\n",
      "|       1| Toy Story (1995)| 01-Jan-1995|                  |http://us.imdb.co...|\n",
      "|       2| GoldenEye (1995)| 01-Jan-1995|                  |http://us.imdb.co...|\n",
      "|       3|Four Rooms (1995)| 01-Jan-1995|                  |http://us.imdb.co...|\n",
      "|       4|Get Shorty (1995)| 01-Jan-1995|                  |http://us.imdb.co...|\n",
      "|       5|   Copycat (1995)| 01-Jan-1995|                  |http://us.imdb.co...|\n",
      "+--------+-----------------+------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define schema\n",
    "movie_schema = StructType([\n",
    "    StructField(\"movie_id\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"release_date\", StringType(), True),\n",
    "    StructField(\"video_release_date\", StringType(), True),\n",
    "    StructField(\"imdb_url\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load data (only first 5 columns from u.item)\n",
    "movies_rdd = spark.sparkContext.textFile(\"/Users/pavethraavadiar/Documents/Masters - Sem 2/Data management/project 3/ml-100k/u.item\")\n",
    "movies_parsed = movies_rdd.map(lambda x: x.split(\"|\")).map(lambda fields: (\n",
    "    int(fields[0]),\n",
    "    fields[1],\n",
    "    fields[2],\n",
    "    fields[3],\n",
    "    fields[4]\n",
    "))\n",
    "\n",
    "movies_df = spark.createDataFrame(movies_parsed, schema=movie_schema)\n",
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a4b32c2-1284-4b99-a4fb-12dc6c2c30e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- video_release_date: string (nullable = true)\n",
      " |-- imdb_url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14670e89-9415-4de9-a05a-d88b047538c1",
   "metadata": {},
   "source": [
    "## Writing movies data into Cassandra\n",
    "Saving the processed movies DataFrame into the 'movielens' keyspace under the 'movies' table in Cassandra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e50115c9-fc1f-488b-8f3f-676c809128e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .options(table=\"movies\", keyspace=\"movielens\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b35b5a-ce7e-45f1-bc58-dffc00950237",
   "metadata": {},
   "source": [
    "## Confirm persistence by reloading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95b71f87-fabf-4c6d-8166-4b4db78b76c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"movies\", keyspace=\"movielens\") \\\n",
    "    .load()\n",
    "\n",
    "movies_df.createOrReplaceTempView(\"movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33353c-cbf2-48e8-b8c7-9993a448fce8",
   "metadata": {},
   "source": [
    "## Loading and Processing Ratings data ('u.data')\n",
    "Importing the ratings data, defining the scheme, and exclusing the timestamp as it's not needed for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80d85a66-ffff-47b5-b5c5-b3af298159ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"movie_id\", IntegerType(), True),\n",
    "    StructField(\"rating\", IntegerType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5fa518-494e-46a7-b41c-86dfe2264e7c",
   "metadata": {},
   "source": [
    "Next, the rating data is loaded and the timestamp field is discarded, because this field is often not needed for average rating analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e4707ab-8319-4621-97b2-73db8954cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = spark.read \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .schema(ratings_schema) \\\n",
    "    .csv(\"/Users/pavethraavadiar/Documents/Masters - Sem 2/Data management/project 3/ml-100k/u.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74bda52b-4ab2-46f8-9d7c-f973d53ae178",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_df.drop(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5840ac3-b67a-470b-afa0-ad6f42f5f7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n",
      "+-------+--------+------+\n",
      "|user_id|movie_id|rating|\n",
      "+-------+--------+------+\n",
      "|    196|     242|     3|\n",
      "|    186|     302|     3|\n",
      "|     22|     377|     1|\n",
      "|    244|      51|     2|\n",
      "|    166|     346|     1|\n",
      "+-------+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.printSchema()\n",
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cb8b3b-1a52-488f-8a14-395053839378",
   "metadata": {},
   "source": [
    "## Writing ratings data into Cassandra\n",
    "\n",
    "In the following code, the ratings DataFrame is persisted into Cassandra keyspace 'movielens' under the 'ratings' table for effcient querying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d09978c-2e24-4285-b212-c806e77a4b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ratings_df.select(\"user_id\", \"movie_id\", \"rating\") \\\n",
    "    .write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .options(table=\"ratings\", keyspace=\"movielens\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597abb92-555a-4da4-a5e9-9bf3a6bb3b55",
   "metadata": {},
   "source": [
    "## Verifying Ratings data from Cassandra\n",
    "\n",
    "Reading the ratings table back from Cassandra to confirm successful data persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cda6dd35-e989-4274-b51b-8268af3bcf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+------+---------+\n",
      "|movie_id|user_id|rating|timestamp|\n",
      "+--------+-------+------+---------+\n",
      "|    1657|    727|     3|     null|\n",
      "|    1443|    225|     4|     null|\n",
      "|    1443|    254|     4|     null|\n",
      "|    1443|    429|     2|     null|\n",
      "|    1443|    551|     5|     null|\n",
      "+--------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"ratings\", keyspace=\"movielens\") \\\n",
    "    .load()\n",
    "\n",
    "ratings_df.createOrReplaceTempView(\"ratings\")\n",
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b45a8f19-db7c-4407-926a-3bb4a6f4f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|movie_id|avg_rating|\n",
      "+--------+----------+\n",
      "|       1|      3.88|\n",
      "|       2|      3.21|\n",
      "|       3|      3.03|\n",
      "|       4|      3.55|\n",
      "|       5|       3.3|\n",
      "|       6|      3.58|\n",
      "|       7|       3.8|\n",
      "|       8|       4.0|\n",
      "|       9|       3.9|\n",
      "|      10|      3.83|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT movie_id, ROUND(AVG(rating), 2) AS avg_rating\n",
    "    FROM ratings\n",
    "    GROUP BY movie_id\n",
    "    ORDER BY movie_id\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990659ac-022a-4e39-810d-9dd72b7061c5",
   "metadata": {},
   "source": [
    "## Question i) Calculate the average rating for each movie.\n",
    "\n",
    "This query joins ratings with movie titles and calculates the average rating grouped by movie_id. It then orders the result to display top-rated movies. This helps identify general user preferences. This is done to understand user rating behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06370a77-e22c-4ea1-8ca8-3d35124ef9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------------------------------------+----------+\n",
      "|movie_id|title                                               |avg_rating|\n",
      "+--------+----------------------------------------------------+----------+\n",
      "|1       |Toy Story (1995)                                    |3.88      |\n",
      "|2       |GoldenEye (1995)                                    |3.21      |\n",
      "|3       |Four Rooms (1995)                                   |3.03      |\n",
      "|4       |Get Shorty (1995)                                   |3.55      |\n",
      "|5       |Copycat (1995)                                      |3.3       |\n",
      "|6       |Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)|3.58      |\n",
      "|7       |Twelve Monkeys (1995)                               |3.8       |\n",
      "|8       |Babe (1995)                                         |4.0       |\n",
      "|9       |Dead Man Walking (1995)                             |3.9       |\n",
      "|10      |Richard III (1995)                                  |3.83      |\n",
      "+--------+----------------------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        r.movie_id, \n",
    "        m.title, \n",
    "        ROUND(AVG(r.rating), 2) AS avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movie_id = m.movie_id\n",
    "    GROUP BY r.movie_id, m.title\n",
    "    ORDER BY r.movie_id\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e876bc43-6361-4000-bd33-79ac53f26a40",
   "metadata": {},
   "source": [
    "## Question ii) Identify the top ten movies with the highest average ratings.\n",
    "\n",
    "This query joins movie info with ratings to show the top 10 highest-rated movies. This is to gather insights on user preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a197b49-5103-407f-8222-870cca8f82f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------------------------------------+----------+-----------+\n",
      "|movie_id|title                                            |avg_rating|num_ratings|\n",
      "+--------+-------------------------------------------------+----------+-----------+\n",
      "|1293    |Star Kid (1997)                                  |5.0       |3          |\n",
      "|1189    |Prefontaine (1997)                               |5.0       |3          |\n",
      "|1500    |Santa with Muscles (1996)                        |5.0       |2          |\n",
      "|1467    |Saint of Fort Washington, The (1993)             |5.0       |2          |\n",
      "|1536    |Aiqing wansui (1994)                             |5.0       |1          |\n",
      "|1122    |They Made Me a Criminal (1939)                   |5.0       |1          |\n",
      "|1653    |Entertaining Angels: The Dorothy Day Story (1996)|5.0       |1          |\n",
      "|814     |Great Day in Harlem, A (1994)                    |5.0       |1          |\n",
      "|1201    |Marlene Dietrich: Shadow and Light (1996)        |5.0       |1          |\n",
      "|1599    |Someone Else's America (1995)                    |5.0       |1          |\n",
      "+--------+-------------------------------------------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        m.movie_id, \n",
    "        m.title, \n",
    "        ROUND(AVG(r.rating), 2) AS avg_rating,\n",
    "        COUNT(r.rating) AS num_ratings\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movie_id = m.movie_id\n",
    "    GROUP BY m.movie_id, m.title\n",
    "    ORDER BY avg_rating DESC, num_ratings DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dde9cc1c-05f5-4324-b091-9a4cafd6b120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------------------------------------+----------+\n",
      "|movie_id|title                                            |avg_rating|\n",
      "+--------+-------------------------------------------------+----------+\n",
      "|1536    |Aiqing wansui (1994)                             |5.0       |\n",
      "|1653    |Entertaining Angels: The Dorothy Day Story (1996)|5.0       |\n",
      "|814     |Great Day in Harlem, A (1994)                    |5.0       |\n",
      "|1201    |Marlene Dietrich: Shadow and Light (1996)        |5.0       |\n",
      "|1189    |Prefontaine (1997)                               |5.0       |\n",
      "|1467    |Saint of Fort Washington, The (1993)             |5.0       |\n",
      "|1500    |Santa with Muscles (1996)                        |5.0       |\n",
      "|1599    |Someone Else's America (1995)                    |5.0       |\n",
      "|1293    |Star Kid (1997)                                  |5.0       |\n",
      "|1122    |They Made Me a Criminal (1939)                   |5.0       |\n",
      "+--------+-------------------------------------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        m.movie_id,\n",
    "        m.title,\n",
    "        ROUND(AVG(r.rating), 2) AS avg_rating\n",
    "    FROM ratings r\n",
    "    JOIN movies m ON r.movie_id = m.movie_id\n",
    "    GROUP BY m.movie_id, m.title\n",
    "    ORDER BY avg_rating DESC, m.title ASC\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f107521a-7c75-46bc-bebc-7b125ac55e1a",
   "metadata": {},
   "source": [
    "## Question iii) Find the users who have rated at least 50 movies and identify their favourite movie genres.\n",
    "\n",
    "The goal is to identify users who have rated at least 50 movies and determine their favorite genre based on frequency of genres they rated. This helps to understand user preferences based on their engagement with different movie genres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e65f3cc-e5d4-4118-a274-f8cb380bcc4b",
   "metadata": {},
   "source": [
    "In the next step, comprehensive schema including all 19 genres is created. This enables multi-label genre analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d27813f0-db4d-42ac-9a0d-8e3b95d43d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = [\n",
    "    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\", \"Crime\", \n",
    "    \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \n",
    "    \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a4d3dbc-3cfe-442d-9e10-4136a870bec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+------------+------------------+------------------------------------------------------+-------+------+---------+---------+--------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+\n",
      "|movie_id|title            |release_date|video_release_date|imdb_url                                              |unknown|action|adventure|animation|children|comedy|crime|documentary|drama|fantasy|film_noir|horror|musical|mystery|romance|sci_fi|thriller|war|western|\n",
      "+--------+-----------------+------------+------------------+------------------------------------------------------+-------+------+---------+---------+--------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+\n",
      "|1       |Toy Story (1995) |01-Jan-1995 |null              |http://us.imdb.com/M/title-exact?Toy%20Story%20(1995) |0      |0     |0        |1        |1       |1     |0    |0          |0    |0      |0        |0     |0      |0      |0      |0     |0       |0  |0      |\n",
      "|2       |GoldenEye (1995) |01-Jan-1995 |null              |http://us.imdb.com/M/title-exact?GoldenEye%20(1995)   |0      |1     |1        |0        |0       |0     |0    |0          |0    |0      |0        |0     |0      |0      |0      |0     |1       |0  |0      |\n",
      "|3       |Four Rooms (1995)|01-Jan-1995 |null              |http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0      |0     |0        |0        |0       |0     |0    |0          |0    |0      |0        |0     |0      |0      |0      |0     |1       |0  |0      |\n",
      "|4       |Get Shorty (1995)|01-Jan-1995 |null              |http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0      |1     |0        |0        |0       |1     |0    |0          |1    |0      |0        |0     |0      |0      |0      |0     |0       |0  |0      |\n",
      "|5       |Copycat (1995)   |01-Jan-1995 |null              |http://us.imdb.com/M/title-exact?Copycat%20(1995)     |0      |0     |0        |0        |0       |0     |1    |0          |1    |0      |0        |0     |0      |0      |0      |0     |1       |0  |0      |\n",
      "+--------+-----------------+------------+------------------+------------------------------------------------------+-------+------+---------+---------+--------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/21 16:18:22 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Start Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Load u.item with genres\") \\\n",
    "    .config(\"spark.cassandra.connection.host\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "genre_fields = [StructField(g.lower().replace(\"-\", \"_\"), IntegerType(), True) for g in genres]\n",
    "item_schema = StructType([\n",
    "    StructField(\"movie_id\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"release_date\", StringType(), True),\n",
    "    StructField(\"video_release_date\", StringType(), True),\n",
    "    StructField(\"imdb_url\", StringType(), True),\n",
    "] + genre_fields)\n",
    "\n",
    "# Load the file\n",
    "movies_with_genres_df = spark.read \\\n",
    "    .option(\"delimiter\", \"|\") \\\n",
    "    .schema(item_schema) \\\n",
    "    .csv(\"/Users/pavethraavadiar/Documents/Masters - Sem 2/Data management/project 3/ml-100k/u.item\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "movies_with_genres_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e21cd65c-ce71-4e3c-956b-e101eed6b15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = false)\n",
      " |-- imdb_url: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- video_release_date: string (nullable = true)\n",
      "\n",
      "+--------+-----------------------------------------------------+------------+-----------------------------+------------------+\n",
      "|movie_id|imdb_url                                             |release_date|title                        |video_release_date|\n",
      "+--------+-----------------------------------------------------+------------+-----------------------------+------------------+\n",
      "|1657    |http://us.imdb.com/M/title-exact?Target%20(1995)     |28-Feb-1996 |Target (1995)                |                  |\n",
      "|1443    |http://us.imdb.com/M/title-exact?8%20Seconds%20(1994)|01-Jan-1994 |8 Seconds (1994)             |                  |\n",
      "|1062    |http://us.imdb.com/M/title-exact?imdb-title-119815   |23-Jan-1998 |Four Days in September (1997)|                  |\n",
      "|1090    |http://us.imdb.com/M/title-exact?Sliver%20(1993)     |01-Jan-1993 |Sliver (1993)                |                  |\n",
      "|1210    |http://us.imdb.com/M/title-exact?Virtuosity%20(1995) |01-Jan-1995 |Virtuosity (1995)            |                  |\n",
      "+--------+-----------------------------------------------------+------------+-----------------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.printSchema()\n",
    "movies_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2aa832f1-352f-4f06-aa03-bd372dba2cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_id', 'imdb_url', 'release_date', 'title', 'video_release_date']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b4a8bfc-0617-45f3-a1bc-ceb51e0f0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_columns = [\n",
    "    'unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy',\n",
    "    'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "    'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'\n",
    "]\n",
    "\n",
    "item_schema = ['movie_id', 'movie_title', 'release_date', 'video_release_date', 'imdb_url'] + genre_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4af783ba-aecd-49e7-afe3-effb831d298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = spark.read \\\n",
    "    .option(\"delimiter\", \"|\") \\\n",
    "    .csv(\"/Users/pavethraavadiar/Documents/Masters - Sem 2/Data management/project 3/ml-100k/u.item\") \\\n",
    "    .toDF(*item_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0273199-0beb-414c-bcd0-c4482fcb13a9",
   "metadata": {},
   "source": [
    "In the next step, an array column genres_array is built to store genre labels. Then it is converted to a comma-separated string. This transformation simplifies filtering and aggregation by genre later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b7c5cc8-d789-4b72-b05a-f7cdfe684041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of genre names where the flag is 1\n",
    "genre_exprs = [when(col(g) == 1, lit(g)).otherwise(lit(None)) for g in genre_columns]\n",
    "movies_df = movies_df.withColumn(\"genres_array\", array(*genre_exprs))\n",
    "\n",
    "# Flatten genres_array to a comma-separated string (optional)\n",
    "from pyspark.sql.functions import concat_ws\n",
    "movies_df = movies_df.withColumn(\"genres\", concat_ws(\",\", col(\"genres_array\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f8155f5-a7af-4f18-8a6d-db4c4350b1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/21 16:18:22 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-----------+\n",
      "|user_id|favourite_genre|genre_count|\n",
      "+-------+---------------+-----------+\n",
      "|1      |Drama          |39         |\n",
      "|2      |Drama          |13         |\n",
      "|3      |Drama          |6          |\n",
      "|5      |Comedy         |28         |\n",
      "|6      |Drama          |48         |\n",
      "|7      |Drama          |51         |\n",
      "|8      |Action,Thriller|6          |\n",
      "|10     |Drama          |34         |\n",
      "|11     |Comedy         |27         |\n",
      "|12     |Drama          |8          |\n",
      "+-------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register temp views\n",
    "ratings_df.createOrReplaceTempView(\"ratings\")\n",
    "movies_df.createOrReplaceTempView(\"movies\")\n",
    "\n",
    "# Qiii: Users with ≥50 ratings and their favourite genre\n",
    "spark.sql(\"\"\"\n",
    "    WITH user_rating_counts AS (\n",
    "        SELECT user_id, COUNT(*) AS num_ratings\n",
    "        FROM ratings\n",
    "        GROUP BY user_id\n",
    "        HAVING num_ratings >= 50\n",
    "    ),\n",
    "    user_genres AS (\n",
    "        SELECT r.user_id, m.genres, COUNT(*) AS genre_count\n",
    "        FROM ratings r\n",
    "        JOIN movies m ON r.movie_id = m.movie_id\n",
    "        JOIN user_rating_counts u ON r.user_id = u.user_id\n",
    "        GROUP BY r.user_id, m.genres\n",
    "    ),\n",
    "    ranked_genres AS (\n",
    "        SELECT user_id, genres, genre_count,\n",
    "               ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY genre_count DESC) AS rank\n",
    "        FROM user_genres\n",
    "    )\n",
    "    SELECT user_id, genres AS favourite_genre, genre_count\n",
    "    FROM ranked_genres\n",
    "    WHERE rank = 1\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b5cbb8-4f88-41fe-be0e-2c3ca6079c54",
   "metadata": {},
   "source": [
    "## Question iv) Find all the users who are less than 20 years old.\n",
    "\n",
    "This is a simple filter to identify younger users and is useful for demographic profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "566e2290-15fb-4491-90bc-19d5d7278edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-------------+--------+\n",
      "|user_id|age|gender|occupation   |zip_code|\n",
      "+-------+---+------+-------------+--------+\n",
      "|30     |7  |M     |student      |55436   |\n",
      "|36     |19 |F     |student      |93117   |\n",
      "|52     |18 |F     |student      |55105   |\n",
      "|57     |16 |M     |none         |84010   |\n",
      "|67     |17 |M     |student      |60402   |\n",
      "|68     |19 |M     |student      |22904   |\n",
      "|101    |15 |M     |student      |05146   |\n",
      "|110    |19 |M     |student      |77840   |\n",
      "|142    |13 |M     |other        |48118   |\n",
      "|179    |15 |M     |entertainment|20755   |\n",
      "+-------+---+------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.createOrReplaceTempView(\"users\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM users \n",
    "    WHERE age < 20\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0dc57-9143-4e09-b89b-67c2799ffe31",
   "metadata": {},
   "source": [
    "## Question v) Find all the users whose occupation is “scientist” and whose age is between 30 and 40 years old.\n",
    "\n",
    "This is a targeted filtering step of professionals by occupation and age group. This shows how Spark SQL supports conditional filtering for insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab89abf6-e98c-428b-a505-1af6f11e4828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+--------+\n",
      "|user_id|age|gender|occupation|zip_code|\n",
      "+-------+---+------+----------+--------+\n",
      "|40     |38 |M     |scientist |27514   |\n",
      "|71     |39 |M     |scientist |98034   |\n",
      "|74     |39 |M     |scientist |T8H1N   |\n",
      "|107    |39 |M     |scientist |60466   |\n",
      "|183    |33 |M     |scientist |27708   |\n",
      "|272    |33 |M     |scientist |53706   |\n",
      "|309    |40 |M     |scientist |70802   |\n",
      "|337    |37 |M     |scientist |10522   |\n",
      "|430    |38 |M     |scientist |98199   |\n",
      "|538    |31 |M     |scientist |21010   |\n",
      "+-------+---+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM users \n",
    "    WHERE occupation = 'scientist' \n",
    "      AND age BETWEEN 30 AND 40\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca437cb0-790f-4e4a-8969-3f0cb1f1fcdb",
   "metadata": {},
   "source": [
    "## Save filtered data to Cassandra\n",
    "\n",
    "Filtered datasets are encouraged to be saved for future analysis or integration with other systems (e.g. dashboards or apps). This reflects practical data analytics skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3eb457fc-b435-43a7-b310-cfa73cf4a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qiv: Users under 20\n",
    "users_under_20 = users_df.filter(users_df.age < 20)\n",
    "\n",
    "# Qv: Scientists between 30 and 40\n",
    "scientists_30_40 = users_df.filter((users_df.occupation == \"scientist\") & (users_df.age >= 30) & (users_df.age <= 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac6da82c-665a-4f8e-b9ca-8263996fb039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write users under 20 to Cassandra\n",
    "users_under_20.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .options(table=\"users_under_20\", keyspace=\"movielens\") \\\n",
    "    .save()\n",
    "\n",
    "# Write scientists aged 30–40 to Cassandra\n",
    "scientists_30_40.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .options(table=\"scientists_30_40\", keyspace=\"movielens\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff3981-aaee-468d-9606-09fda51294d4",
   "metadata": {},
   "source": [
    "## Verifying Data Saved in Cassandra\n",
    "\n",
    "Reading data back from Cassandra ensures that the data was written and saved correctly and can be reused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cdb1fa6f-9024-4ff8-9a0a-43fc89568cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+-------------+--------+\n",
      "|user_id|age|gender|   occupation|zip_code|\n",
      "+-------+---+------+-------------+--------+\n",
      "|    375| 17|     M|entertainment|   37777|\n",
      "|    851| 18|     M|        other|   29646|\n",
      "|    859| 18|     F|        other|   06492|\n",
      "|    813| 14|     F|      student|   02136|\n",
      "|     52| 18|     F|      student|   55105|\n",
      "|    397| 17|     M|      student|   27514|\n",
      "|    257| 17|     M|      student|   77005|\n",
      "|    425| 19|     M|      student|   58644|\n",
      "|    110| 19|     M|      student|   77840|\n",
      "|    849| 15|     F|      student|   25652|\n",
      "|    729| 19|     M|      student|   56567|\n",
      "|    221| 19|     M|      student|   20685|\n",
      "|    368| 18|     M|      student|   92113|\n",
      "|    507| 18|     F|       writer|   28450|\n",
      "|    624| 19|     M|      student|   30067|\n",
      "|    592| 18|     M|      student|   97520|\n",
      "|    434| 16|     F|      student|   49705|\n",
      "|    631| 18|     F|      student|   38866|\n",
      "|    787| 18|     F|      student|   98620|\n",
      "|    646| 17|     F|      student|   51250|\n",
      "+-------+---+------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+---+------+----------+--------+\n",
      "|user_id|age|gender|occupation|zip_code|\n",
      "+-------+---+------+----------+--------+\n",
      "|    874| 36|     M| scientist|   37076|\n",
      "|    643| 39|     M| scientist|   55122|\n",
      "|    543| 33|     M| scientist|   95123|\n",
      "|    337| 37|     M| scientist|   10522|\n",
      "|    554| 32|     M| scientist|   62901|\n",
      "|     40| 38|     M| scientist|   27514|\n",
      "|     71| 39|     M| scientist|   98034|\n",
      "|    272| 33|     M| scientist|   53706|\n",
      "|    430| 38|     M| scientist|   98199|\n",
      "|    538| 31|     M| scientist|   21010|\n",
      "|    107| 39|     M| scientist|   60466|\n",
      "|    918| 40|     M| scientist|   70116|\n",
      "|    183| 33|     M| scientist|   27708|\n",
      "|    730| 31|     F| scientist|   32114|\n",
      "|     74| 39|     M| scientist|   T8H1N|\n",
      "|    309| 40|     M| scientist|   70802|\n",
      "+-------+---+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read back to confirm\n",
    "under_20_df = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"users_under_20\", keyspace=\"movielens\") \\\n",
    "    .load()\n",
    "\n",
    "scientists_df = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"scientists_30_40\", keyspace=\"movielens\") \\\n",
    "    .load()\n",
    "\n",
    "under_20_df.show()\n",
    "scientists_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808fd49-27d9-48f4-a10a-01647ebef25a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "All required datasets were loaded, processed, and persisted into Cassandra. The SQL queries answered the assignment questions with the top 10 results displayed as requested. Moreover, filtered datasets were also saved for future analysis, with verification steps confirming data integrity. Therefore, this notebook demonstrates end-to-end data analysis using Spark and Cassandra on the MovieLens 100K dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sparkenv38)",
   "language": "python",
   "name": "sparkenv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
